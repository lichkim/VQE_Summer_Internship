{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pennylane as qml\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#시드 고정\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "##### 수기로 작성된 0 데이터. 데이터는 [여기](https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits)에서 다운 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    \"\"\"Pytorch dataloader for the Optical Recognition of Handwritten Digits Data Set\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, label=0, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.csv_file = csv_file\n",
    "        self.transform = transform\n",
    "        self.df = self.filter_by_label(label)\n",
    "\n",
    "    def filter_by_label(self, label):\n",
    "        # Use pandas to return a dataframe of only zeros\n",
    "        df = pd.read_csv(self.csv_file)\n",
    "        df = df.loc[df.iloc[:, -1] == label]\n",
    "        return df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.df.iloc[idx, :-1] / 16\n",
    "        image = np.array(image)\n",
    "        image = image.astype(np.float32).reshape(8, 8)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and label\n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pytorch의 DataLoader 인스턴스를 만들어주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 8  # Height / width of the square images\n",
    "batch_size = 1\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = DigitsDataset(csv_file=\"./datasets/optdigits.tra\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,2))\n",
    "\n",
    "for i in range(8):\n",
    "    image = dataset[i][0].reshape(image_size,image_size)\n",
    "    plt.subplot(1,8,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.numpy(), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator(판별자) 생성\n",
    "##### Discriminator는 2개의 Hidden Layer로 구성된 Fully Connected Layer로 구성합니다. Discriminator는 Classical한 Neural Network입니다. Discriminator의 Output은 Input이 실제 데이터인지를 나타내는 확률입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Fully connected classical discriminator\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # Inputs to first hidden layer (num_input_features -> 64)\n",
    "            nn.Linear(image_size * image_size, 64),\n",
    "            nn.ReLU(),\n",
    "            # First hidden layer (64 -> 16)\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            # Second hidden layer (16 -> output)\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator(생성자) 구현\n",
    "\n",
    "##### 각각의 보조 생성자(sub-generator), $G^{(i)}$는 아래의 그림처럼 회로 구성을 가집니다. 전반적인 양자 생성자는 $N_{G}$개의 보조 생성자로 구성되며, 각각은 $N$개의 큐비트들로 이루어져 있습니다. 잠재 벡터(latent vector)입력에서 이미지 출력까지의 프로세스는 4개의 특징적인 세션으로 구분 할 수 있습니다: state embedding, parametrisation, non-linear transformation, 그리고 post-processing. 각각의 섹션들은 간단하게 하기 위해 한 훈련 과정의 한번의 반복을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) State Embedding\n",
    "##### 잠재 벡터, $z \\in \\mathbb{R}^{N}$는 $\\left[ 0, \\pi/2 \\right)$범위의 uniform distribution에서 샘플링됩니다. 모든 보조 생성자는 RY게이트를 통해 Angle임베딩된 같은 잠재 벡터를 받습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Parameterized Layers\n",
    "##### parameterized layer는 RY게이트와 Z게이트로 이루어져 있습니다. 이 레이어는 총 $D$번 반복됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
